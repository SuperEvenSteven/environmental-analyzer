package com.ohair.stephen.edp;

import java.util.List;

import org.apache.beam.sdk.Pipeline;
import org.apache.beam.sdk.coders.StringUtf8Coder;
import org.apache.beam.sdk.io.TextIO;
import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO;
import org.apache.beam.sdk.options.PipelineOptionsFactory;
import org.apache.beam.sdk.transforms.Create;
import org.apache.beam.sdk.transforms.DoFn;
import org.apache.beam.sdk.transforms.ParDo;
import org.apache.beam.sdk.values.PCollection;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.cloud.public_datasets.nexrad2.GcsNexradL2List;
import com.google.cloud.public_datasets.nexrad2.NexRadUtils;
import com.ohair.stephen.edp.model.CombinedDataModel;
import com.ohair.stephen.edp.model.GSODDataModel;
import com.ohair.stephen.edp.model.NexRadDataModel;
import com.ohair.stephen.edp.transform.GSODTransform;
import com.ohair.stephen.edp.transform.NexRadTransform;

/**
 * Pipeline that extracts GSOD records from Google BigQuery and combines them
 * with NexRAD Level II tar files from google storage to create a CSV output
 * file. Runs in batch since the rate at which the data is updated doesn't
 * warrant streaming.
 * 
 * Based from the BigQueryTornado<a href=
 * "https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/BigQueryTornadoes.java">[1]</a>
 * and NexRAD<a href=
 * "https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/nexrad2/src/com/google/cloud/public_datasets/nexrad2/APPipeline.java"
 * >[2]</a> examples found on GitHub.
 * 
 * @author Stephen O'Hair
 * @see <a href=
 *      "https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/cookbook/BigQueryTornadoes.java">attribution</a></br>
 *      <a href=
 *      "https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/nexrad2/src/com/google/cloud/public_datasets/nexrad2/APPipeline.java">attribution</a>
 */
public final class BatchProcessPipeline {

	private static final Logger log = LoggerFactory.getLogger(BatchProcessPipeline.class);

	/**
	 * Join the GSOD and NexRad collections, using station name code as the key.
	 */
	private static PCollection<CombinedDataModel> joinDataSets(PCollection<GSODDataModel> gsodDataModel,
			PCollection<NexRadDataModel> nexRadDataModel) {

		/*
		 * final TupleTag<String> eventInfoTag = new TupleTag<String>(); final
		 * TupleTag<String> countryInfoTag = new TupleTag<String>();
		 * 
		 * // transform both input collections to tuple collections, where the keys are
		 * country // codes in both cases. PCollection<KV<String, String>> eventInfo =
		 * eventsTable.apply( ParDo.of(new ExtractEventDataFn()));
		 * PCollection<KV<String, String>> countryInfo = countryCodes.apply(
		 * ParDo.of(new ExtractCountryInfoFn()));
		 * 
		 * // country code 'key' -> CGBKR (<event info>, <country name>)
		 * PCollection<KV<String, CoGbkResult>> kvpCollection = KeyedPCollectionTuple
		 * .of(eventInfoTag, eventInfo) .and(countryInfoTag, countryInfo)
		 * .apply(CoGroupByKey.<String>create());
		 * 
		 * // Process the CoGbkResult elements generated by the CoGroupByKey transform.
		 * // country code 'key' -> string of <event info>, <country name>
		 * PCollection<KV<String, String>> finalResultCollection =
		 * kvpCollection.apply(ParDo.named("Process").of( new DoFn<KV<String,
		 * CoGbkResult>, KV<String, String>>() {
		 * 
		 * @Override public void processElement(ProcessContext c) { KV<String,
		 * CoGbkResult> e = c.element(); String countryCode = e.getKey(); String
		 * countryName = "none"; countryName = e.getValue().getOnly(countryInfoTag); for
		 * (String eventInfo : c.element().getValue().getAll(eventInfoTag)) { //
		 * Generate a string that combines information from both collection values
		 * c.output(KV.of(countryCode, "Country name: " + countryName + ", Event info: "
		 * + eventInfo)); } } }));
		 * 
		 * // write to GCS PCollection<String> formattedResults = finalResultCollection
		 * .apply(ParDo.named("Format").of(new DoFn<KV<String, String>, String>() {
		 * 
		 * @Override public void processElement(ProcessContext c) { String outputstring
		 * = "Country code: " + c.element().getKey() + ", " + c.element().getValue();
		 * c.output(outputstring); } })); return formattedResults;
		 */
		throw new RuntimeException("not yet implemented!");
	}

	/**
	 * Runs the pipeline batch process.
	 * 
	 * @param options
	 *            - specified at runtime
	 * @throws Exception
	 */
	private static void runBatchProcess(BatchProcessOptions options) {
		// specify temp location based on output location
		options.setTempLocation(options.getOutput() + "staging");

		Pipeline p = Pipeline.create(options);

		// Creates a collection of all NexRAD tar files required to satisfy the
		// specified Years, Months and Days specified in {@link
		// BatchProcessOptions}.
		@SuppressWarnings("serial")
		PCollection<String> nexRadTarFiles = p//
				.apply("getParams", Create.of(NexRadUtils.getTarNameParams(options)).withCoder(StringUtf8Coder.of())) //
				.apply("getArchives", ParDo.of(new DoFn<String, String>() {
					@ProcessElement
					public void processElement(ProcessContext c) throws Exception {
						String[] params = c.element().split(",");
						String radar = params[0];
						int year = Integer.parseInt(params[1]);
						int month = Integer.parseInt(params[2]);
						int day = Integer.parseInt(params[3]);
						List<String> files = GcsNexradL2List.getFiles(radar, year, month, day);
						log.info(files.size() + " files for " + radar + " " + year + "-" + month + "-" + day);
						for (String file : files) {
							c.output(file);
						}
					}
				}));

		// rebundle the tars 1000 each so they can be parallelized out to more workers
		nexRadTarFiles = NexRadUtils.rebundle("rebundle", nexRadTarFiles, 1000);

		/**
		 * Apply data source transformation to models
		 */

		// take the nexRadTarFiles collection and transform them into a
		// CombinedDataModel
		PCollection<NexRadDataModel> nexRadDataset = nexRadTarFiles //
				.apply("processNexRadTarFiles", new NexRadTransform()); //

		// Reads all GSOD rows for the given
		PCollection<GSODDataModel> gsodDataset = p.apply(BigQueryIO.readTableRows() //
				.from(options.getInput())) //
				.apply("precipitationTransform", new GSODTransform()); //

		// .apply(BigQueryIO.writeTableRows() //
		// .to(options.getOutput()).withSchema(CombinedDataModel.tableSchema())//
		// .withCreateDisposition(BigQueryIO.Write.CreateDisposition.CREATE_IF_NEEDED)
		// //
		// .withWriteDisposition(BigQueryIO.Write.WriteDisposition.WRITE_TRUNCATE));

		/**
		 * Combine the two datasets together
		 */
		PCollection<CombinedDataModel> dataModel = joinDataSets(gsodDataset, nexRadDataset);
		// dataModel.apply("saveModelAsCsv", TextIO.write().to(options.getOutput())//
		// .withSuffix(".csv").withoutSharding());

		p.run().waitUntilFinish();
	}

	/*
	 * Main entry point.
	 */
	public static void main(String[] args) throws Exception {
		BatchProcessOptions options = PipelineOptionsFactory.fromArgs(args).withValidation()
				.as(BatchProcessOptions.class);

		runBatchProcess(options);
	}
}
